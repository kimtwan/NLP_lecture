{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 5-2. **Sentiment Analysis**"
      ],
      "metadata": {
        "id": "f2-B3vJjYEiV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jhe8Wwyg_Bpe",
        "outputId": "a743454c-5d5b-4eb0-fed1-51dcb76affca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q nltk\n",
        "!pip install -q konlpy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment analysis ([Vader](https://github.com/cjhutto/vaderSentiment))"
      ],
      "metadata": {
        "id": "no3HKviRLEbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "CocN_iA39Nc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b092ca0f-0429-419b-ced0-90877469c5f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize Vader sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "sentences = [\n",
        "                'I really hate you.',\n",
        "                \"I don't like you.\",\n",
        "                'I am a student.',\n",
        "                'I like you.',\n",
        "                'I love you very much.'\n",
        "            ]\n",
        "\n",
        "for sentence in sentences:\n",
        "    print('sentence :', sentence)\n",
        "    print('sentiments:', sia.polarity_scores(sentence))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT2gsYA99bL8",
        "outputId": "0671d556-77e1-480b-e45b-3e127ae59f20"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence : I really hate you.\n",
            "sentiments: {'neg': 0.666, 'neu': 0.334, 'pos': 0.0, 'compound': -0.6115}\n",
            "\n",
            "sentence : I don't like you.\n",
            "sentiments: {'neg': 0.513, 'neu': 0.487, 'pos': 0.0, 'compound': -0.2755}\n",
            "\n",
            "sentence : I am a student.\n",
            "sentiments: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "\n",
            "sentence : I like you.\n",
            "sentiments: {'neg': 0.0, 'neu': 0.286, 'pos': 0.714, 'compound': 0.3612}\n",
            "\n",
            "sentence : I love you very much.\n",
            "sentiments: {'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'compound': 0.6369}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Korean sentiment analysis ([eKoNLPy](https://github.com/entelecheia/eKoNLPy))"
      ],
      "metadata": {
        "id": "KYCKRBcF-PYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/entelecheia/eKoNLPy.git\n",
        "%cd eKoNLPy/\n",
        "!pip install .\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4psSt5C1fdm7",
        "outputId": "9ed09938-0c21-45c2-837c-9b052498cdd3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'eKoNLPy'...\n",
            "remote: Enumerating objects: 4386, done.\u001b[K\n",
            "remote: Counting objects: 100% (796/796), done.\u001b[K\n",
            "remote: Compressing objects: 100% (316/316), done.\u001b[K\n",
            "remote: Total 4386 (delta 492), reused 691 (delta 411), pack-reused 3590\u001b[K\n",
            "Receiving objects: 100% (4386/4386), 74.24 MiB | 19.91 MiB/s, done.\n",
            "Resolving deltas: 100% (3110/3110), done.\n",
            "/content/eKoNLPy\n",
            "Processing /content/eKoNLPy\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.6 in /usr/local/lib/python3.10/dist-packages (from eKoNLPy==2.0.4) (8.1.7)\n",
            "Collecting fugashi<2.0.0,>=1.3.0 (from eKoNLPy==2.0.4)\n",
            "  Downloading fugashi-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (600 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m600.9/600.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mecab-ko-dic<2.0.0,>=1.0.0 (from eKoNLPy==2.0.4)\n",
            "  Downloading mecab-ko-dic-1.0.0.tar.gz (33.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.2/33.2 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from eKoNLPy==2.0.4) (3.8.1)\n",
            "Requirement already satisfied: pandas<=2.2.2,>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from eKoNLPy==2.0.4) (2.0.3)\n",
            "Requirement already satisfied: scipy<=1.13.0,>1.10.0 in /usr/local/lib/python3.10/dist-packages (from eKoNLPy==2.0.4) (1.11.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->eKoNLPy==2.0.4) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->eKoNLPy==2.0.4) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->eKoNLPy==2.0.4) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<=2.2.2,>=1.5.3->eKoNLPy==2.0.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=2.2.2,>=1.5.3->eKoNLPy==2.0.4) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=2.2.2,>=1.5.3->eKoNLPy==2.0.4) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<=2.2.2,>=1.5.3->eKoNLPy==2.0.4) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<=2.2.2,>=1.5.3->eKoNLPy==2.0.4) (1.16.0)\n",
            "Building wheels for collected packages: eKoNLPy, mecab-ko-dic\n",
            "  Building wheel for eKoNLPy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for eKoNLPy: filename=ekonlpy-2.0.4-py3-none-any.whl size=10253603 sha256=950d378976a6db57fcdbde03f8fc20d9b00e136f00cd1ef92dc37b16f00813af\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ztoerqr9/wheels/86/8a/58/97001bb273b6e988301c99b893f814fadb553b44471f34ede5\n",
            "  Building wheel for mecab-ko-dic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-ko-dic: filename=mecab_ko_dic-1.0.0-py3-none-any.whl size=33424393 sha256=9b61ebdc8afb452c788ae038cbded27709a2a08a3ae6ae8bcf82f99d7edbfcd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/46/b8/996432c9998690a5a66fb82f6499222e48a23ff5b6c7d80322\n",
            "Successfully built eKoNLPy mecab-ko-dic\n",
            "Installing collected packages: mecab-ko-dic, fugashi, eKoNLPy\n",
            "Successfully installed eKoNLPy-2.0.4 fugashi-1.3.2 mecab-ko-dic-1.0.0\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ekonlpy.sentiment import KSA\n",
        "\n",
        "sentences = [\n",
        "        '오늘은 날씨가 맑아서 기분이 너무나 좋다.',\n",
        "        '물가가 너무 올라서 살기가 힘들다.',\n",
        "        '매일 KOSPI 지수가 하락하고 있고, 환율은 매일 치솟고 있다.'\n",
        "        ]\n",
        "\n",
        "# initialize Korean sentiment analyzer\n",
        "ksa = KSA()\n",
        "\n",
        "for sentence in sentences:\n",
        "    tokens = ksa.tokenize(sentence)\n",
        "    score = ksa.get_score(tokens)\n",
        "    print(sentence)\n",
        "    print(score)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxJ51rNTUQ4M",
        "outputId": "90b7bac7-a5ec-4d4a-b425-94fa8f49ceaa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오늘은 날씨가 맑아서 기분이 너무나 좋다.\n",
            "{'Positive': 1, 'Negative': -6, 'Polarity': -0.7142856122449125, 'Subjectivity': 0.9999998571428775}\n",
            "\n",
            "물가가 너무 올라서 살기가 힘들다.\n",
            "{'Positive': 0, 'Negative': -4, 'Polarity': -0.9999997500000625, 'Subjectivity': 0.9999997500000625}\n",
            "\n",
            "매일 KOSPI 지수가 하락하고 있고, 환율은 매일 치솟고 있다.\n",
            "{'Positive': 1, 'Negative': -2, 'Polarity': -0.33333322222225925, 'Subjectivity': 0.9999996666667778}\n",
            "\n"
          ]
        }
      ]
    }
  ]
}