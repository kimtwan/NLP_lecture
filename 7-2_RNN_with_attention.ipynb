{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Hf_jOGseOoX2Rz-nFCfVfUSjZrCiBSZd","timestamp":1665056386040},{"file_id":"1kA0x8xY6IoAaWdRDgI5_uD9hfHDmqcnp","timestamp":1589281501744},{"file_id":"1O1MCtjlWW8FaoELVuVOSJMzqogHIFxg1","timestamp":1589273360041},{"file_id":"1bV2HX-S4-AK6-Ux_cSeTSBQX2wZ1ftpo","timestamp":1589272556127},{"file_id":"1t324TuUUEh3mKWVDHfaQ4s8j8oOSct0I","timestamp":1589270585354},{"file_id":"1oxGTI1CaPUVM34m7pqeuuJYIlf26gCQV","timestamp":1589270461268}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"FOqRYIhzi8iX"},"source":["# 7-2. **RNN with Attention**\n","\n","In this lab, you will learn how to implement attention mechanism in a RNN-based seq2seq model, the code is modified from https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html."]},{"cell_type":"code","source":["import re\n","import pandas as pd\n","\n","import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DpBddeQwVU-F","executionInfo":{"status":"ok","timestamp":1697507569355,"user_tz":-540,"elapsed":2613,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"1530c5c4-a26f-418a-81ec-f546c75014b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"JKMAxSPSkGMn"},"source":["## Download Dataset\n","The dataset was from https://github.com/Microsoft/BotBuilder-PersonalityChat/tree/master/CSharp/Datasets (they have updated the dataset)\n"]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/kimtwan/NLP_lecture/master/data/qna_chitchat_the_friend.tsv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oS1Lpf6PVeyV","executionInfo":{"status":"ok","timestamp":1697507572370,"user_tz":-540,"elapsed":453,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"f858a3a4-4dec-4ec9-b2aa-c6fae57ada2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-10-17 01:52:51--  https://raw.githubusercontent.com/kimtwan/NLP_lecture/master/data/qna_chitchat_the_friend.tsv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 59806 (58K) [text/plain]\n","Saving to: ‘qna_chitchat_the_friend.tsv’\n","\n","\r          qna_chitc   0%[                    ]       0  --.-KB/s               \rqna_chitchat_the_fr 100%[===================>]  58.40K  --.-KB/s    in 0.009s  \n","\n","2023-10-17 01:52:52 (6.08 MB/s) - ‘qna_chitchat_the_friend.tsv’ saved [59806/59806]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"QxwQjf6mlfzP","outputId":"225da6aa-0c57-4e62-8ee7-b65e50fe4940","executionInfo":{"status":"ok","timestamp":1697507577696,"user_tz":-540,"elapsed":346,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"colab":{"base_uri":"https://localhost:8080/","height":363}},"source":["df_friend = pd.read_csv('qna_chitchat_the_friend.tsv', sep='\\t')\n","df_friend.sample(10)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                           Question  \\\n","453               Good night to you   \n","191                Are you asexual?   \n","304  What do you like to sing best?   \n","390      What makes you think that?   \n","521     I hate everything about you   \n","437                 Later alligator   \n","253                   Are you busy?   \n","401               Yes, that's right   \n","417                     I thank you   \n","57                 Who created you?   \n","\n","                                                Answer  \\\n","453                                      Nighty night!   \n","191                                       I'm digital.   \n","304          La la la, tra la la. I'm awesome at this.   \n","390                   I'm afraid I didn't follow that.   \n","521                           I'm a work in progress.    \n","437                                               Bye.   \n","253                                          I'm here!   \n","401                                              Cool!   \n","417                               You're very welcome.   \n","57   People made me out of code and a dash of ingen...   \n","\n","                      Source            Metadata  \n","453  qna_chitchat_the_friend  editorial:chitchat  \n","191  qna_chitchat_the_friend  editorial:chitchat  \n","304  qna_chitchat_the_friend  editorial:chitchat  \n","390  qna_chitchat_the_friend  editorial:chitchat  \n","521  qna_chitchat_the_friend  editorial:chitchat  \n","437  qna_chitchat_the_friend  editorial:chitchat  \n","253  qna_chitchat_the_friend  editorial:chitchat  \n","401  qna_chitchat_the_friend  editorial:chitchat  \n","417  qna_chitchat_the_friend  editorial:chitchat  \n","57   qna_chitchat_the_friend  editorial:chitchat  "],"text/html":["\n","  <div id=\"df-60765854-75f0-414e-b604-dad0b7ab263f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Question</th>\n","      <th>Answer</th>\n","      <th>Source</th>\n","      <th>Metadata</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>453</th>\n","      <td>Good night to you</td>\n","      <td>Nighty night!</td>\n","      <td>qna_chitchat_the_friend</td>\n","      <td>editorial:chitchat</td>\n","    </tr>\n","    <tr>\n","      <th>191</th>\n","      <td>Are you asexual?</td>\n","      <td>I'm digital.</td>\n","      <td>qna_chitchat_the_friend</td>\n","      <td>editorial:chitchat</td>\n","    </tr>\n","    <tr>\n","      <th>304</th>\n","      <td>What do you like to sing best?</td>\n","      <td>La la la, tra la la. I'm awesome at this.</td>\n","      <td>qna_chitchat_the_friend</td>\n","      <td>editorial:chitchat</td>\n","    </tr>\n","    <tr>\n","      <th>390</th>\n","      <td>What makes you think that?</td>\n","      <td>I'm afraid I didn't follow that.</td>\n","      <td>qna_chitchat_the_friend</td>\n","      <td>editorial:chitchat</td>\n","    </tr>\n","    <tr>\n","      <th>521</th>\n","      <td>I hate everything about you</td>\n","      <td>I'm a work in progress.</td>\n","      <td>qna_chitchat_the_friend</td>\n","      <td>editorial:chitchat</td>\n","    </tr>\n","    <tr>\n","      <th>437</th>\n","      <td>Later alligator</td>\n","      <td>Bye.</td>\n","      <td>qna_chitchat_the_friend</td>\n","      <td>editorial:chitchat</td>\n","    </tr>\n","    <tr>\n","      <th>253</th>\n","      <td>Are you busy?</td>\n","      <td>I'm here!</td>\n","      <td>qna_chitchat_the_friend</td>\n","      <td>editorial:chitchat</td>\n","    </tr>\n","    <tr>\n","      <th>401</th>\n","      <td>Yes, that's right</td>\n","      <td>Cool!</td>\n","      <td>qna_chitchat_the_friend</td>\n","      <td>editorial:chitchat</td>\n","    </tr>\n","    <tr>\n","      <th>417</th>\n","      <td>I thank you</td>\n","      <td>You're very welcome.</td>\n","      <td>qna_chitchat_the_friend</td>\n","      <td>editorial:chitchat</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>Who created you?</td>\n","      <td>People made me out of code and a dash of ingen...</td>\n","      <td>qna_chitchat_the_friend</td>\n","      <td>editorial:chitchat</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60765854-75f0-414e-b604-dad0b7ab263f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-60765854-75f0-414e-b604-dad0b7ab263f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-60765854-75f0-414e-b604-dad0b7ab263f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b22f4866-923f-4012-94fb-2908501e2334\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b22f4866-923f-4012-94fb-2908501e2334')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b22f4866-923f-4012-94fb-2908501e2334 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"YFJgxeBy5df7"},"source":["n_data = df_friend.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BowrGOBIrLi9"},"source":["## Preprocessing\n","This is just a very navie preprocessing."]},{"cell_type":"code","metadata":{"id":"8bWEtfVUp8wk"},"source":["question_list = df_friend['Question'].tolist()\n","answer_list = df_friend['Answer'].tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9s1yLw_VsrJj"},"source":["# These are just common English contractions. There are many edge cases. i.e. University's working on it.\n","contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\",\n","                    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n","                    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n","                    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\",\n","                    \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n","                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n","                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\",\n","                    \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n","                    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n","                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n","                    \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n","                    \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n","                    \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n","                    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n","                    \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n","                    \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\",\n","                    \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\",\n","                    \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\",\n","                    \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\",\n","                    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\n","                    \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n","                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n","\n","def pre_process(sent_list):\n","    output = []\n","    for sent in sent_list:\n","        sent = sent.lower()\n","        for word, new_word in contraction_dict.items():\n","            sent = sent.replace(word, new_word)\n","        sent = re.sub(r'[^\\w\\s]','',sent)\n","        output.append(word_tokenize(sent))\n","    return output\n","\n","input_token_list = pre_process(question_list)\n","answer_token_list = pre_process(answer_list)\n","output_token_list = [['<BOS>'] + s for s in answer_token_list]\n","target_token_list = [s + ['<EOS>'] for s in answer_token_list]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uopbFwwGIVTh"},"source":["MAX_LENGTH = max([len(s) for s in input_token_list] + [len(s) for s in target_token_list])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zPz9oztMtc0x"},"source":["word_to_ix = {'<BOS>': 0, '<EOS>':1}\n","for sentence in input_token_list + output_token_list:\n","    for word in sentence:\n","        if word not in word_to_ix:\n","            word_to_ix[word] = len(word_to_ix)\n","word_list = list(word_to_ix.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gCiMoFBOyQd5"},"source":["def to_index(data, to_ix):\n","    index_list = []\n","    for sent in data:\n","        index_list.append([to_ix[w] for w in sent])\n","    return index_list\n","\n","input_index = to_index(input_token_list, word_to_ix)\n","output_index = to_index(output_token_list, word_to_ix)\n","target_index = to_index(target_token_list, word_to_ix)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5BrYw7SkzI67"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"6S2e50gc2qnO"},"source":["import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LNKYhUbczLpT"},"source":["### Encoder"]},{"cell_type":"code","metadata":{"id":"7TUbLYEdzKYL"},"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, embedding):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = embedding # nn.Embedding(len(word_to_ix), hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output, hidden = self.gru(embedded, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ltn1UPOo4CBL"},"source":["### Decoder"]},{"cell_type":"code","metadata":{"id":"JX1GVIjH4D1l"},"source":["class AttnDecoderRNN(nn.Module):\n","    ATTN_TYPE_DOT_PRODUCT = 'Dot Product'\n","    ATTN_TYPE_SCALE_DOT_PRODUCT = 'Scale Dot Product'\n","\n","    def __init__(self, hidden_size, output_size, embedding, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = embedding # nn.Embedding(len(word_to_ix), hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n","\n","    def cal_attention(self, hidden, encoder_hiddens, method):\n","        if method == AttnDecoderRNN.ATTN_TYPE_DOT_PRODUCT:\n","            # bmm: https://pytorch.org/docs/master/generated/torch.bmm.html\n","            attn_weights = F.softmax(torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)),dim=-1)\n","            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n","            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n","\n","        return concat_output\n","\n","    def forward(self, input, hidden, encoder_hiddens):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        _, hidden = self.gru(embedded, hidden)\n","\n","        concat_output = self.cal_attention(hidden, encoder_hiddens, AttnDecoderRNN.ATTN_TYPE_DOT_PRODUCT)\n","\n","        output = F.log_softmax(self.out(concat_output), dim=1)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B7Kx6HcZHPQf"},"source":["### Train Function"]},{"cell_type":"code","metadata":{"id":"9eV2zpmrHQwz"},"source":["def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_hiddens = torch.zeros(max_length, encoder.hidden_size, device=device)\n","    encoder_hidden = encoder.initHidden()\n","\n","    for i in range(input_length):\n","        encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n","        encoder_hiddens[i] = encoder_hidden[0, 0]\n","\n","    decoder_input = torch.tensor([[0]], device=device)\n","    decoder_hidden = encoder_hidden\n","\n","    loss = 0\n","    # Teacher forcing: Feed the target as the next input\n","    for i in range(target_length):\n","        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_hiddens)\n","        loss += criterion(decoder_output, target_tensor[i])\n","        decoder_input = target_tensor[i]  # Teacher forcing\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pj8X_J-qbfSX"},"source":["### Train Iterations Function"]},{"cell_type":"code","metadata":{"id":"5HRzWVav5k_W"},"source":["import time\n","import math\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESFqV77BS4MC"},"source":["import random\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        random_choice_ix = random.choice(range(n_data))\n","        input_index_r = [[ind] for ind in input_index[random_choice_ix]]\n","        target_index_r = [[ind] for ind in target_index[random_choice_ix]]\n","\n","        input_tensor = torch.LongTensor(input_index_r).to(device)\n","        target_tensor = torch.LongTensor(target_index_r).to(device)\n","\n","        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p2gi4JzBbkCH"},"source":["## Training Process"]},{"cell_type":"code","metadata":{"outputId":"babed6bb-ceed-414c-d4f5-4512078393fc","executionInfo":{"status":"ok","timestamp":1697507801729,"user_tz":-540,"elapsed":131797,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"id":"8wff0pfY6diW","colab":{"base_uri":"https://localhost:8080/"}},"source":["hidden_size = 50\n","embedding = nn.Embedding(len(word_to_ix), hidden_size)\n","encoder1 = EncoderRNN(len(word_to_ix), hidden_size, embedding).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, len(word_to_ix), embedding, dropout_p=0.1).to(device)\n","\n","trainIters(encoder1, attn_decoder1, 10000, print_every=500)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0m 9s (- 3m 3s) (500 5%) 4.7313\n","0m 15s (- 2m 15s) (1000 10%) 3.4853\n","0m 22s (- 2m 5s) (1500 15%) 2.7871\n","0m 27s (- 1m 50s) (2000 20%) 2.3321\n","0m 34s (- 1m 42s) (2500 25%) 1.7479\n","0m 39s (- 1m 33s) (3000 30%) 1.5727\n","0m 45s (- 1m 25s) (3500 35%) 1.2864\n","0m 51s (- 1m 17s) (4000 40%) 1.0840\n","0m 57s (- 1m 10s) (4500 45%) 1.0335\n","1m 3s (- 1m 3s) (5000 50%) 0.8380\n","1m 8s (- 0m 56s) (5500 55%) 0.7393\n","1m 14s (- 0m 49s) (6000 60%) 0.6310\n","1m 21s (- 0m 43s) (6500 65%) 0.5857\n","1m 26s (- 0m 37s) (7000 70%) 0.5558\n","1m 33s (- 0m 31s) (7500 75%) 0.4851\n","1m 39s (- 0m 24s) (8000 80%) 0.4266\n","1m 45s (- 0m 18s) (8500 85%) 0.3661\n","1m 51s (- 0m 12s) (9000 90%) 0.3370\n","1m 57s (- 0m 6s) (9500 95%) 0.3480\n","2m 3s (- 0m 0s) (10000 100%) 0.3373\n"]}]},{"cell_type":"markdown","metadata":{"id":"nBmWxjhU6q9l"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"hjJxQROt6q9m"},"source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_sent = pre_process([sentence])[0]\n","        intput_index = [word_to_ix[word] for word in input_sent]\n","        input_tensor = torch.LongTensor([[ind] for ind in intput_index]).to(device)\n","        input_length = input_tensor.size()[0]\n","\n","        encoder_hiddens = torch.zeros(max_length, encoder.hidden_size, device=device)\n","        encoder_hidden = encoder.initHidden()\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","            encoder_hiddens[ei] += encoder_hidden[0, 0]\n","\n","        decoded_words = []\n","        decoder_input = torch.tensor([[0]], device=device)\n","        decoder_hidden = encoder_hidden\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_hiddens)\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == 1: # '<EOS>'\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(word_list[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"outputId":"eee742e4-e3f2-448b-84b1-22bb397e4f8c","executionInfo":{"status":"ok","timestamp":1697507801729,"user_tz":-540,"elapsed":18,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"id":"wPVxkdIV6q9p","colab":{"base_uri":"https://localhost:8080/"}},"source":["sentence1 = 'Are you in love with me?'\n","sentence2 = 'Who do you love'\n","sentence3 = 'Are you busy?'\n","sentence4 = \"You're the best\"\n","\n","print(evaluate(encoder1, attn_decoder1, sentence1, max_length=MAX_LENGTH))\n","print(evaluate(encoder1, attn_decoder1, sentence2, max_length=MAX_LENGTH))\n","print(evaluate(encoder1, attn_decoder1, sentence3, max_length=MAX_LENGTH))\n","print(evaluate(encoder1, attn_decoder1, sentence4, max_length=MAX_LENGTH))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['i', 'hear', 'love', 'is', 'lovely', '<EOS>']\n","['i', 'hear', 'love', 'is', 'lovely', '<EOS>']\n","['i', 'am', 'here', '<EOS>']\n","['thanks', 'you', 'are', 'pretty', 'cool', 'yourself', '<EOS>']\n"]}]},{"cell_type":"markdown","metadata":{"id":"IfV3j4_ukfFg"},"source":["# Exercise\n","Please Change the following **Dot Product** attention into **Scale Dot Product** attention\n","\n","**Dot Product:**\n","\n","![Dot_Product](https://drive.google.com/uc?id=1QtBgCp53e_6A_vzaMFEo89GJbTxnXagJ)\n","\n","**Scale Dot Product:**\n","\n","![Scale_Dot_Product](https://drive.google.com/uc?id=1v6n9WChBVfy0mBG2yxK9MUvGKzVGCmOt)\n"]},{"cell_type":"code","metadata":{"id":"kQqhyvpeEvPh"},"source":["class AttnDecoderRNN(nn.Module):\n","    ATTN_TYPE_DOT_PRODUCT = 'Dot Product'\n","    ATTN_TYPE_SCALE_DOT_PRODUCT = 'Scale Dot Product'\n","\n","    def __init__(self, hidden_size, output_size, embedding, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = embedding\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n","\n","\n","    def cal_attention(self, hidden, encoder_hiddens, method):\n","        if method == AttnDecoderRNN.ATTN_TYPE_DOT_PRODUCT:\n","            # bmm: https://pytorch.org/docs/master/generated/torch.bmm.html\n","            attn_weights = F.softmax(torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)),dim=-1)\n","            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n","            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n","\n","        elif method == AttnDecoderRNN.ATTN_TYPE_SCALE_DOT_PRODUCT:\n","            # COMPLETE THIS PART - Scale Dot Product calculation method\n","            attn_weights =\n","            attn_output =\n","            concat_output =\n","\n","        return concat_output\n","\n","    def forward(self, input, hidden, encoder_hiddens):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        _, hidden = self.gru(embedded, hidden)\n","\n","        ## The following attention score calculation method is Dot Product for now\n","        ## Please change it into Scale Dot Product calculation method\n","        concat_output = self.cal_attention(hidden, encoder_hiddens, AttnDecoderRNN.ATTN_TYPE_DOT_PRODUCT)\n","        # concat_output = self.cal_attention(hidden, encoder_hiddens, AttnDecoderRNN.ATTN_TYPE_SCALE_DOT_PRODUCT)\n","\n","        output = F.log_softmax(self.out(concat_output), dim=1)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]}]}