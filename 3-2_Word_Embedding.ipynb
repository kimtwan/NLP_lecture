{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vNJ9kB71bpeSgDbVVqeGJQq0fU45pOPR","timestamp":1664983622137},{"file_id":"1KAKtDBYF2wnI7fwi6s5c4jMNdd6pVoLw","timestamp":1583799548264},{"file_id":"1wzoM1nC-14lfT2u7TiP04kZ3Zyj8c9_7","timestamp":1583789973808},{"file_id":"18knyJzepDkWCbnUqXBJEMj9_U9mhwIVA","timestamp":1583590040968},{"file_id":"1ZAeZOj__wcFSKcYJatR1yjc9Bi67KhFc","timestamp":1552031451265},{"file_id":"13FLHZ7OObuYidE0CKjrPcDgIa9rBKbq4","timestamp":1551931926160},{"file_id":"10AdEgRqTFA7HnYWkL_cfOEwFZIUZsOJz","timestamp":1551699141093}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GCHPkKbuhPF6"},"source":["# 3-2. **Word Embedding**"]},{"cell_type":"code","metadata":{"id":"GNyhgK5QTOuD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697471155657,"user_tz":-540,"elapsed":3292,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"1cc12486-2e5e-4f6e-80d8-67e234ab3df5"},"source":["import re\n","import pprint\n","from lxml import etree\n","from gensim.models import Word2Vec\n","\n","import nltk\n","from nltk import word_tokenize, sent_tokenize\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"0isQ539cf_nI"},"source":["## Word2Vec"]},{"cell_type":"markdown","metadata":{"id":"FIPpEvI4kqMV"},"source":["### Data Preprocessing"]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/kimtwan/NLP_lecture/master/data/ted_en-20160408.zip\n","!unzip ted_en-20160408.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hwEFiZJflQh9","executionInfo":{"status":"ok","timestamp":1697497065046,"user_tz":-540,"elapsed":1176,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"112a6a90-2134-488f-9e93-64d1fcdb18a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-10-16 22:57:43--  https://raw.githubusercontent.com/kimtwan/NLP_lecture/master/data/ted_en-20160408.zip\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 16595708 (16M) [application/zip]\n","Saving to: ‘ted_en-20160408.zip’\n","\n","ted_en-20160408.zip 100%[===================>]  15.83M  --.-KB/s    in 0.1s    \n","\n","2023-10-16 22:57:44 (120 MB/s) - ‘ted_en-20160408.zip’ saved [16595708/16595708]\n","\n","Archive:  ted_en-20160408.zip\n","  inflating: ted_en-20160408.xml     \n"]}]},{"cell_type":"code","source":["targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n","\n","# Getting contents of <content> tag from the xml file\n","target_text = etree.parse(targetXML)\n","parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n","\n","# Removing 'Sound-effect labels' using regular expression (i.e. (Audio), (Laughter))\n","content_text = re.sub(r'\\([^)]*\\)', '', parse_text)"],"metadata":{"id":"CDw631iQxthA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["content_text[:1000]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"TXyw2OGo4U8_","executionInfo":{"status":"ok","timestamp":1697471165776,"user_tz":-540,"elapsed":394,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"2688f988-22f5-426d-b151-2066465b2cdc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Here are two reasons companies fail: they only do more of the same, or they only do what's new.\\nTo me the real, real solution to quality growth is figuring out the balance between two activities: exploration and exploitation. Both are necessary, but it can be too much of a good thing.\\nConsider Facit. I'm actually old enough to remember them. Facit was a fantastic company. They were born deep in the Swedish forest, and they made the best mechanical calculators in the world. Everybody used them. And what did Facit do when the electronic calculator came along? They continued doing exactly the same. In six months, they went from maximum revenue ... and they were gone. Gone.\\nTo me, the irony about the Facit story is hearing about the Facit engineers, who had bought cheap, small electronic calculators in Japan that they used to double-check their calculators.\\n\\nFacit did too much exploitation. But exploration can go wild, too.\\nA few years back, I worked closely alongside a European biotech co\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"VYmEQgB7XoDE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697471225459,"user_tz":-540,"elapsed":57719,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"987808d1-6d97-455e-b6ed-0d7168c3eb54"},"source":["# Tokenizing the sentence to process it by using NLTK library\n","sent_text = sent_tokenize(content_text)\n","\n","# Removing punctuations and changing all characters to lower case\n","normalized_text = []\n","for string in sent_text:\n","     tokens = re.sub(r'[^a-z0-9]+', ' ', string.lower())\n","     normalized_text.append(tokens)\n","\n","# Tokenising each sentence to process individual word\n","sentences = [word_tokenize(sentence) for sentence in normalized_text]\n","\n","# Prints only 10 (tokenized) sentences\n","print(sentences[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new'], ['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation'], ['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing'], ['consider', 'facit'], ['i', 'm', 'actually', 'old', 'enough', 'to', 'remember', 'them'], ['facit', 'was', 'a', 'fantastic', 'company'], ['they', 'were', 'born', 'deep', 'in', 'the', 'swedish', 'forest', 'and', 'they', 'made', 'the', 'best', 'mechanical', 'calculators', 'in', 'the', 'world'], ['everybody', 'used', 'them'], ['and', 'what', 'did', 'facit', 'do', 'when', 'the', 'electronic', 'calculator', 'came', 'along'], ['they', 'continued', 'doing', 'exactly', 'the', 'same']]\n"]}]},{"cell_type":"markdown","metadata":{"id":"CojV1MbhkQxK"},"source":["### Word2Vec - Continuous Bag-Of-Words (CBOW)"]},{"cell_type":"code","metadata":{"id":"zW1iEee3lZC9"},"source":["wv_cbow_model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=5, workers=4, sg=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2FKp3X7pkRm6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697471260166,"user_tz":-540,"elapsed":5,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"82c311ee-3c58-4bec-87ed-d442f1f04635"},"source":["similar_words = wv_cbow_model.wv.most_similar('man')\n","pprint.pprint(similar_words)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('woman', 0.8458347916603088),\n"," ('guy', 0.8152571320533752),\n"," ('lady', 0.7929542064666748),\n"," ('boy', 0.7698023915290833),\n"," ('girl', 0.7342793345451355),\n"," ('soldier', 0.700160801410675),\n"," ('kid', 0.6862170696258545),\n"," ('friend', 0.6859571933746338),\n"," ('gentleman', 0.6858844757080078),\n"," ('rabbi', 0.6655703783035278)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"dsFHg0znlPSf"},"source":["### Word2Vec - Skip Gram"]},{"cell_type":"code","metadata":{"id":"k16AowhCWUXu"},"source":["wv_sg_model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=5, workers=4, sg=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e8UiVfr2cBtA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697471357738,"user_tz":-540,"elapsed":26,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"93d2135f-3d95-4277-bca6-c5d56074e330"},"source":["similar_words = wv_sg_model.wv.most_similar('man')\n","pprint.pprint(similar_words)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('woman', 0.7723897099494934),\n"," ('soldier', 0.7161628603935242),\n"," ('guy', 0.715850293636322),\n"," ('rabbi', 0.6964094042778015),\n"," ('gentleman', 0.6705251932144165),\n"," ('son', 0.6702896356582642),\n"," ('testament', 0.669889509677887),\n"," ('imam', 0.6672779321670532),\n"," ('lady', 0.6609430313110352),\n"," ('pianist', 0.6547991633415222)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"NfF7YqvpppbG"},"source":["## Word2Vec vs FastText"]},{"cell_type":"markdown","metadata":{"id":"d8IV7D6VAEcr"},"source":["Let's try to find out the difference between Word2Vec and FastText\n","\n","Word2Vec - Skipgram cannot find similar word 'electrofishing' as 'electrofishing' is not in the vocabulary - so you can see the error"]},{"cell_type":"code","source":["similar_words = wv_sg_model.wv.most_similar('electrofishing')\n","pprint.pprint(similar_words)"],"metadata":{"id":"OqO67BGG77z0","colab":{"base_uri":"https://localhost:8080/","height":338},"executionInfo":{"status":"error","timestamp":1697471357738,"user_tz":-540,"elapsed":24,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"4cf9a66a-43f6-499a-a5ea-f36a83fa0dc0"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-64081bffd8f6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimilar_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwv_sg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'electrofishing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilar_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         all_keys = [\n\u001b[1;32m    843\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"Key 'electrofishing' not present in vocabulary\""]}]},{"cell_type":"markdown","metadata":{"id":"5TpkScI8sA9G"},"source":["### FastText - Skip Gram\n","\n","You can find that FastText works extremely well"]},{"cell_type":"code","metadata":{"id":"YAqOR1Vqps6M"},"source":["from gensim.models import FastText"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kqkvyiUw_DRh"},"source":["ft_sg_model = FastText(sentences, vector_size=100, window=5, min_count=5, workers=4, sg=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kv26QObJriB7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697471598292,"user_tz":-540,"elapsed":9,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"ce7c0bac-5ffa-462c-ce5f-b358715b046d"},"source":["result = ft_sg_model.wv.most_similar('electrofishing')\n","pprint.pprint(result)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('electrolux', 0.87488853931427),\n"," ('electrolyte', 0.8718639016151428),\n"," ('electroshock', 0.854791522026062),\n"," ('electro', 0.8501136302947998),\n"," ('electroencephalogram', 0.8373817205429077),\n"," ('electrochemical', 0.828506350517273),\n"," ('electrogram', 0.8282065391540527),\n"," ('airbus', 0.8261869549751282),\n"," ('airbag', 0.8261586427688599),\n"," ('electron', 0.8198568224906921)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"X0x2aQpfsFSx"},"source":["### FastText - Continuous Bag-Of-Words (CBOW)"]},{"cell_type":"code","metadata":{"id":"BUBqvqpc2sbL"},"source":["ft_cbow_model = FastText(sentences, vector_size=100, window=5, min_count=5, workers=4, sg=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kUj1RUzM2nLA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697471715391,"user_tz":-540,"elapsed":27,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"b1dc142e-a4c1-4f0b-d8f3-242c3e61ab4c"},"source":["result = ft_cbow_model.wv.most_similar('electrofishing')\n","pprint.pprint(result)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('fishing', 0.9164567589759827),\n"," ('flushing', 0.9054871797561646),\n"," ('licensing', 0.9021921157836914),\n"," ('refreshing', 0.8997875452041626),\n"," ('smashing', 0.8992639183998108),\n"," ('flourishing', 0.8991420269012451),\n"," ('flashing', 0.8969458341598511),\n"," ('vanishing', 0.8963451385498047),\n"," ('transplanting', 0.895754337310791),\n"," ('recycling', 0.8953123688697815)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"6hjmOhmRi7Ov"},"source":["## King + Woman - Man = ?"]},{"cell_type":"markdown","metadata":{"id":"Xw7b9OSwjGm0"},"source":["Try both CBOW and Skip Gram model to calculate 'King - Man + Woman = ?'"]},{"cell_type":"code","metadata":{"id":"ovTXjSdgrw36","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697471715391,"user_tz":-540,"elapsed":16,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"669ad922-8ed6-483d-a0cc-00bacae8784c"},"source":["result = wv_cbow_model.wv.most_similar(positive=['king' , 'woman'], negative=['man'], topn=1)\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('president', 0.7923591732978821)]\n"]}]},{"cell_type":"code","metadata":{"id":"gUtbE2jwq1to","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697471715392,"user_tz":-540,"elapsed":12,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"ebab85e6-c827-43b7-ef77-a12902f75996"},"source":["result = wv_sg_model.wv.most_similar(positive=['king' , 'woman'], negative=['man'], topn=1)\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('queen', 0.6769269108772278)]\n"]}]},{"cell_type":"code","metadata":{"id":"3PWf2I4_WZpG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697471715392,"user_tz":-540,"elapsed":9,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"6a189afc-ff81-4cf2-8a46-4ecf3f3e4d00"},"source":["result = ft_cbow_model.wv.most_similar(positive=['king' , 'woman'], negative=['man'], topn=1)\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('kidding', 0.8963255286216736)]\n"]}]},{"cell_type":"code","metadata":{"id":"j9x51rRhWZrx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697471715392,"user_tz":-540,"elapsed":7,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"eeb502c5-1172-4280-9a8d-ec4a66f19b53"},"source":["result = ft_sg_model.wv.most_similar(positive=['king' , 'woman'], negative=['man'], topn=1)\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('hawking', 0.6837846636772156)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"KpAd8t-wjTMA"},"source":["This is not what we expected...Probably not enough data to answer as 'Queen'\n"]},{"cell_type":"markdown","metadata":{"id":"pqLruu6247Ze"},"source":["# Play with Colab Form Fields\n","**The Form** supports multiple types of fields, including **input fields**, **dropdown menus**.\n","\n","You can edit this section by double-clicking it.\n","\n","Let's get familiar by changing the value in each input field (on the right) and checking the changes in the code (on the left) - vice versa"]},{"cell_type":"code","metadata":{"id":"XBNvQmee5QIG","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665020290503,"user_tz":-540,"elapsed":307,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"a2b29357-0330-48ec-da83-0fa1a8fd4b8d"},"source":["# @title Example form fields\n","# @markdown please put description\n","\n","string = 'examples'  # @param {type: 'string'}\n","slider_value = 143  # @param {type: 'slider', min: 100, max: 200}\n","number = 10253  # @param {type: 'number'}\n","date = '2020-01-05'  # @param {type: 'date'}\n","pick_me = 'tuesday'  # @param ['monday', 'tuesday', 'wednesday', 'thursday']\n","select_or_input = 'apples' # @param ['apples', 'bananas', 'oranges'] {allow-input: true}\n","\n","\n","# print the output\n","print('string is',string)\n","print('slider_value',slider_value)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["string is examplesddeddd\n","slider_value 143\n"]}]},{"cell_type":"markdown","metadata":{"id":"DupJY3rOcozM"},"source":["# Exercise\n","In this exercise, you need to implement a **'Word Algebra Calculator'  interface** using Word2Vec and FastText trained by the provided TED Scripts. The interface can be built by Colab Form Fields we just learned above.\n","\n","What the users can do through the interface are:\n","\n","\n","1.   Input the word formula in the text field, e.g. King - Man + Woman\n","2.   Select the word embedding model from dropdown menu, either Word2Vec or FastText\n","3.   Select the training architecture from dropdown menu, either CBOW or Skip Gram\n","4.   Get(print out) the resulted word of the input formula by running the form (same to running the code section)\n","\n","\n","\n","Note:\n","1. Please **do not** put the training process into your form section.\n","2. Please make your interface 'user-friendly' and instructional for users to use, e.g. by adding proper explaination or guide\n","3. We will use formula like 'Word1 + Word2 + Word3 - Word4' to test your interface, the number of the words and the sign between each two words can vary.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ur90NpMBStBn"},"source":["## 1.Build your word embedding models"]},{"cell_type":"code","metadata":{"id":"UMpJYtCcHytp"},"source":["## Please generate four different types of word embedding models with TED data\n","## The parameter for all four models: vector_size=100, window=5, min_count=5, workers=4.\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xGrBhxGXTDzF"},"source":["##2.Build your Interface"]},{"cell_type":"markdown","metadata":{"id":"DdEQ0ATwTfUU"},"source":["You can edit the following form elements to build your interface"]},{"cell_type":"code","source":["# @title Word Algebra Calculator\n","\n","# @markdown Please select the model and formula to calculate the word algebra\n","\n","# Get the input\n","\n","\n","# @markdown Now you can activate the Calculator by running this section\n","\n","## 1.choose the corresponding model\n","\n","\n","## 2.processing the formula to extract the postive and negative word list\n","\n","\n","## 3.calculate the formula for an similar word using the selected model\n","\n","\n","## 4.print out the most similar word after\n"],"metadata":{"id":"ginngvM88F5x"},"execution_count":null,"outputs":[]}]}