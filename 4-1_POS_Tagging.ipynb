{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/kimtwan/NLP_lecture/blob/master/4-1_POS_Tagging.ipynb","timestamp":1697554805290},{"file_id":"1NERc2zVLOPBh0UG0bdXlzq6GHjMNDgdE","timestamp":1697175285931},{"file_id":"1Hdna8_xWvybW6VEUtWYmH5gLhfrVsFpB","timestamp":1586238865191},{"file_id":"1wm6nHzob9BXovYFnK1_gM4cDXY8vY4FA","timestamp":1586212047141},{"file_id":"1iKOmT4gVF7EggWsac2FONGuqMkXGtooG","timestamp":1586044515230}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"lHbXdZ0b7_-W"},"source":["# 4-1. **POS Tagging**\n","POS tagging is the process of marking up a word in a corpus to a corresponding part of a speech tag, based on its context and definition. This task is not straightforward, as a particular word may have a different part of speech based on the context in which the word is used"]},{"cell_type":"markdown","metadata":{"id":"o2Yuq_ck8lzM"},"source":["## Regular Expression Tagger\n","\n","The regular expression tagger assigns tags to tokens on the basis of matching patterns. For instance, we might guess that any word ending in ed is the past participle of a verb, and any word ending with 's is a possessive noun. We can express these as a list of regular expressions:\n","\n"]},{"cell_type":"code","metadata":{"id":"J_SNkGVsftLK","outputId":"96b16ea0-847c-4866-8865-688c34744abb","executionInfo":{"status":"ok","timestamp":1697552610663,"user_tz":-540,"elapsed":1935,"user":{"displayName":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["import nltk\n","\n","# Downloading required corpus\n","nltk.download('punkt')\n","nltk.download('brown')\n","\n","from nltk import word_tokenize\n","from nltk.corpus import brown\n","\n","brown_tagged_sents = brown.tagged_sents(categories='news')\n","brown_sents = brown.sents(categories='news')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n"]}]},{"cell_type":"code","metadata":{"id":"7VMB4D7Vfipk"},"source":[" # Define regular expression patterns\n","patterns = [\n","            (r'.*ing$', 'VBG'),               # gerunds\n","            (r'.*ed$', 'VBD'),                # simple past\n","            (r'.*es$', 'VBZ'),                # 3rd singular present\n","            (r'.*ould$', 'MD'),               # modals\n","            (r'.*\\'s$', 'NN$'),               # possessive nouns\n","            (r'.*s$', 'NNS'),                 # plural nouns\n","            (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n","            (r'.*', 'NN')                     # nouns (default)\n","        ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejmC2tSLk3dA","outputId":"d776ef21-fe0e-4048-ddf1-05202d811903","executionInfo":{"status":"ok","timestamp":1697552803947,"user_tz":-540,"elapsed":5,"user":{"displayName":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Build regular expression tagger using the defined patterns\n","regexp_tagger = nltk.RegexpTagger(patterns)\n","\n","# Print one of the sentences\n","print(brown_sents[3])\n","# Print one of the tagged sentences\n","print(regexp_tagger.tag(brown_sents[3]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['``', 'Only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', \"''\", ',', 'the', 'jury', 'said', ',', '``', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', ',', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', \"''\", '.']\n","[('``', 'NN'), ('Only', 'NN'), ('a', 'NN'), ('relative', 'NN'), ('handful', 'NN'), ('of', 'NN'), ('such', 'NN'), ('reports', 'NNS'), ('was', 'NNS'), ('received', 'VBD'), (\"''\", 'NN'), (',', 'NN'), ('the', 'NN'), ('jury', 'NN'), ('said', 'NN'), (',', 'NN'), ('``', 'NN'), ('considering', 'VBG'), ('the', 'NN'), ('widespread', 'NN'), ('interest', 'NN'), ('in', 'NN'), ('the', 'NN'), ('election', 'NN'), (',', 'NN'), ('the', 'NN'), ('number', 'NN'), ('of', 'NN'), ('voters', 'NNS'), ('and', 'NN'), ('the', 'NN'), ('size', 'NN'), ('of', 'NN'), ('this', 'NNS'), ('city', 'NN'), (\"''\", 'NN'), ('.', 'NN')]\n"]}]},{"cell_type":"code","source":["print(brown_tagged_sents[3])"],"metadata":{"id":"f5dkEYOaFQPw","executionInfo":{"status":"ok","timestamp":1697553667490,"user_tz":-540,"elapsed":14,"user":{"displayName":"","userId":""}},"outputId":"6526d6b2-651f-4711-a100-5309ea3df4a5","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('``', '``'), ('Only', 'RB'), ('a', 'AT'), ('relative', 'JJ'), ('handful', 'NN'), ('of', 'IN'), ('such', 'JJ'), ('reports', 'NNS'), ('was', 'BEDZ'), ('received', 'VBN'), (\"''\", \"''\"), (',', ','), ('the', 'AT'), ('jury', 'NN'), ('said', 'VBD'), (',', ','), ('``', '``'), ('considering', 'IN'), ('the', 'AT'), ('widespread', 'JJ'), ('interest', 'NN'), ('in', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('the', 'AT'), ('number', 'NN'), ('of', 'IN'), ('voters', 'NNS'), ('and', 'CC'), ('the', 'AT'), ('size', 'NN'), ('of', 'IN'), ('this', 'DT'), ('city', 'NN'), (\"''\", \"''\"), ('.', '.')]\n"]}]},{"cell_type":"code","metadata":{"id":"V8wT_6a7k63S","outputId":"05fcb8b3-fab7-4e84-bf72-4add616602ae","executionInfo":{"status":"ok","timestamp":1697552823973,"user_tz":-540,"elapsed":1391,"user":{"displayName":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Evaluate the tagger (Calculate the accuracy/performance)\n","regexp_tagger.evaluate(brown_tagged_sents)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-1d58e4831b4d>:2: DeprecationWarning: \n","  Function evaluate() has been deprecated.  Use accuracy(gold)\n","  instead.\n","  regexp_tagger.evaluate(brown_tagged_sents)\n"]},{"output_type":"execute_result","data":{"text/plain":["0.20326391789486245"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["text = 'This race is awesome, I want to race too'"],"metadata":{"id":"vYo7VuQjwX73"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYPlTCtt8s9L","outputId":"67397fcc-c268-4115-f045-f170dc197f6d","executionInfo":{"status":"ok","timestamp":1697552875626,"user_tz":-540,"elapsed":511,"user":{"displayName":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["tokens = word_tokenize(text)\n","\n","print(regexp_tagger.tag(tokens))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('This', 'NNS'), ('race', 'NN'), ('is', 'NNS'), ('awesome', 'NN'), (',', 'NN'), ('I', 'NN'), ('want', 'NN'), ('to', 'NN'), ('race', 'NN'), ('too', 'NN')]\n"]}]},{"cell_type":"markdown","metadata":{"id":"-GLU4cC8r49g"},"source":["## Hidden Markov Models\n","\n","A hidden Markov model (HMM) allows us to talk about both observed events (like words that we see in the input) and hidden events (like part-of-speech tags) that we think of as causal factors in our probabilistic model."]},{"cell_type":"code","metadata":{"id":"w-Uuv3D5YhhS","outputId":"e9bdcbe1-aa95-4523-e248-dc41f1292fca","executionInfo":{"status":"ok","timestamp":1697553454621,"user_tz":-540,"elapsed":15,"user":{"displayName":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Hidden Markov Models in Python\n","# Katrin Erk, March 2013 updated March 2016\n","#\n","# This HMM addresses the problem of part-of-speech tagging. It estimates\n","# the probability of a tag sequence for a given word sequence as follows:\n","#\n","# Say words = w1....wN\n","# and tags = t1..tN\n","#\n","# then\n","# P(tags | words) is_proportional_to product P(ti | t{i-1}) P(wi | ti)\n","#\n","# To find the best tag sequence for a given sequence of words,\n","# we want to find the tag sequence that has the maximum P(tags | words)\n","import nltk\n","import sys\n","nltk.download('brown')\n","\n","from nltk.corpus import brown\n","from nltk.corpus import treebank"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n"]}]},{"cell_type":"code","source":["# Estimating P(wi | ti) from corpus data using Maximum Likelihood Estimation (MLE):\n","# P(wi | ti) = count(wi, ti) / count(ti)\n","#\n","# We add an artificial 'start' tag at the beginning of each sentence, and\n","# We add an artificial 'end' tag at the end of each sentence.\n","# So we start out with the brown tagged sentences,\n","# add the two artificial tags,\n","# and then make one long list of all the tag/word pairs.\n","\n","brown_tags_words = []\n","brown_tagged_sents = brown.tagged_sents()\n","\n","for sent in brown_tagged_sents:\n","    # sent is a list of word/tag pairs\n","    # add START/START at the beginning\n","    brown_tags_words.append(('START', 'START'))\n","    # then all the tag/word pairs for the word/tag pairs in the sentence.\n","    # shorten tags to 2 characters each\n","    brown_tags_words.extend([(tag[:2], word) for (word, tag) in sent])\n","    # then END/END\n","    brown_tags_words.append( ('END', 'END') )\n","\n","# conditional frequency distribution:\n","# count(wi, ti)\n","cfd_tagwords = nltk.ConditionalFreqDist(brown_tags_words)\n","# conditional probability distribution, using\n","# maximum likelihood estimate:\n","# P(wi | ti)\n","cpd_tagwords = nltk.ConditionalProbDist(cfd_tagwords, nltk.MLEProbDist)\n","\n","print('The probability of an adjective (JJ) being \"new\" is', cpd_tagwords['JJ'].prob('new'))\n","print('The probability of a verb (VB) being \"duck\" is', cpd_tagwords['VB'].prob('duck'))"],"metadata":{"id":"6oXRGT5LI_k8"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TO_rZxt1wv2z","outputId":"75e63d74-5c3e-44c7-8871-2970388ce955","executionInfo":{"status":"ok","timestamp":1697553839956,"user_tz":-540,"elapsed":3887,"user":{"displayName":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Estimating P(ti | t{i-1}) from corpus data using Maximum Likelihood Estimation (MLE):\n","# P(ti | t{i-1}) = count(t{i-1}, ti) / count(t{i-1})\n","#\n","brown_tags = [tag for (tag, word) in brown_tags_words ]\n","# make conditional frequency distribution:\n","# count(t{i-1}, ti)\n","cfd_tags= nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))\n","# make conditional probability distribution, using\n","# maximum likelihood estimate:\n","# P(ti | t{i-1})\n","cpd_tags = nltk.ConditionalProbDist(cfd_tags, nltk.MLEProbDist)\n","\n","print('If we have just seen \"DT\", the probability of \"NN\" is', cpd_tags['DT'].prob('NN'))\n","print( 'If we have just seen \"VB\", the probability of \"JJ\" is', cpd_tags['VB'].prob('DT'))\n","print( 'If we have just seen \"VB\", the probability of \"NN\" is', cpd_tags['VB'].prob('NN'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The probability of an adjective (JJ) being \"new\" is 0.01472344917632025\n","The probability of a verb (VB) being \"duck\" is 6.042713350943527e-05\n","If we have just seen \"DT\", the probability of \"NN\" is 0.5057722522030194\n","If we have just seen \"VB\", the probability of \"JJ\" is 0.016885067592065053\n","If we have just seen \"VB\", the probability of \"NN\" is 0.10970977711020183\n"]}]},{"cell_type":"markdown","metadata":{"id":"3cY7cOjnUvMc"},"source":["##  Train HMM Tagger with NLTK HMM Trainer"]},{"cell_type":"code","metadata":{"id":"S8akyRu6qvcr","outputId":"f8eb5a86-8458-4506-a4be-bc44597cb189","executionInfo":{"status":"ok","timestamp":1697553881712,"user_tz":-540,"elapsed":501,"user":{"displayName":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Pretagged training data\n","brown_tagged_sents = brown.tagged_sents()\n","\n","print(brown_tagged_sents)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]\n"]}]},{"cell_type":"code","metadata":{"id":"ftW_G61yqv_T","outputId":"2384f6f6-5c20-4a70-e5ce-444dd7319d9d","executionInfo":{"status":"ok","timestamp":1697553946883,"user_tz":-540,"elapsed":37205,"user":{"displayName":"","userId":""}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["# Import HMM module\n","from nltk.tag import hmm\n","\n","# Setup a trainer with default(None) values\n","# And train with the data\n","trainer = hmm.HiddenMarkovModelTrainer()\n","trained_tagger = trainer.train_supervised(brown_tagged_sents)\n","\n","print (trained_tagger)\n","# Prints the basic data about the tagger\n","\n","tokens = word_tokenize(text)\n","print(trained_tagger.tag(tokens))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<HiddenMarkovModelTagger 472 states and 56057 output symbols>\n","[('This', 'DT'), ('race', 'NN'), ('is', 'BEZ'), ('awesome', 'JJ'), (',', ','), ('I', 'PPSS'), ('want', 'VB'), ('to', 'TO'), ('race', 'VB'), ('too', 'QL')]\n"]}]},{"cell_type":"code","source":["korean_text = '이번 경주는 정말 멋진데, 나도 경주하고 싶다'"],"metadata":{"id":"tbAJvv9Sx8b2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = word_tokenize(korean_text)\n","print(trained_tagger.tag(tokens))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yeaySv3tysFb","executionInfo":{"status":"ok","timestamp":1697473763570,"user_tz":-540,"elapsed":463,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"aa4722fa-d4b0-4658-8704-ed57c11f5f9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('이번', 'AT'), ('경주는', 'AT'), ('정말', 'AT'), ('멋진데', 'AT'), (',', 'AT'), ('나도', 'AT'), ('경주하고', 'AT'), ('싶다', 'AT')]\n"]}]},{"cell_type":"markdown","source":["## POS Tagging for Korean with [Kkma](http://kkma.snu.ac.kr/documents/?doc=postag)"],"metadata":{"id":"IzeHdr1Rwj3X"}},{"cell_type":"code","source":["# Install konlpy\n","!pip install -q konlpy"],"metadata":{"id":"_8oY861Id7P6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697473768904,"user_tz":-540,"elapsed":5338,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"08bc13ec-c62f-492f-822c-e64f04d959ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# Import Kkma module\n","from konlpy.tag import Kkma\n","kkma = Kkma()"],"metadata":{"id":"iizrVZ-HxGNj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokenization\n","tokens = kkma.morphs(text)\n","print(tokens)\n","\n","# POS tagging\n","tags = kkma.pos(text)\n","print(tags)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pusZ9gabx6B1","executionInfo":{"status":"ok","timestamp":1697473790045,"user_tz":-540,"elapsed":18972,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"7e0e3dcd-8ae6-47ea-d95d-92520c41c940"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['This', 'race', 'is', 'awesome', ',', 'I', 'want', 'to', 'race', 'too']\n","[('This', 'OL'), ('race', 'OL'), ('is', 'OL'), ('awesome', 'OL'), (',', 'SP'), ('I', 'OL'), ('want', 'OL'), ('to', 'OL'), ('race', 'OL'), ('too', 'OL')]\n"]}]},{"cell_type":"code","source":["tokens = kkma.morphs(korean_text)\n","print(tokens)\n","\n","tags = kkma.pos(korean_text)\n","print(tags)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRmjGDQgFHmG","executionInfo":{"status":"ok","timestamp":1697473790046,"user_tz":-540,"elapsed":32,"user":{"displayName":"Taewan Kim","userId":"13184421950357533683"}},"outputId":"022edac5-36ce-45b8-ccc8-60ad3de5479c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['이번', '경주', '는', '정말', '멋지', 'ㄴ데', ',', '나도', '경주', '하', '고', '싶', '다']\n","[('이번', 'NNG'), ('경주', 'NNG'), ('는', 'JX'), ('정말', 'MAG'), ('멋지', 'VA'), ('ㄴ데', 'ECE'), (',', 'SP'), ('나도', 'NNG'), ('경주', 'NNG'), ('하', 'XSV'), ('고', 'ECE'), ('싶', 'VXA'), ('다', 'EFN')]\n"]}]}]}